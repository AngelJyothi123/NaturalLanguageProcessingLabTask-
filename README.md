# üß† Natural Language Processing Laboratory  

**Total Duration:** 30 Hours  
**Department:** Computer Science and Engineering  
**Program:** B.Tech - CSE  

---

## üìò **Overview**
This repository contains practical laboratory experiments for the **Natural Language Processing (NLP)** course.  
The goal of these experiments is to understand fundamental NLP concepts such as **tokenization, morphology, n-grams, part-of-speech tagging, chunking,** and **machine translation** using modern tools and libraries in **Python**.  

The experiments are divided into **two parts**:
- **Part 1:** Laboratory Tasks (Hands-on Experiments)
- **Part 2:** Use Cases (Applied NLP Scenarios)

---

## üß© **Part 1 ‚Äî Laboratory Experiments**

### üß± **Task 1: Introduction to Python & NLP**
**Objective:**  
Get familiar with Python programming and core NLP libraries such as NLTK and spaCy.  

**Activities:**  
- Learn Python syntax, loops, and basic data structures.  
- Practice using NLTK and spaCy for basic NLP operations.  

**Tools:**  
Python, NLTK, spaCy, NLP Libraries  

---

### ‚úÇÔ∏è **Task 2: Word Analysis**
**Objective:**  
Perform word-level analysis using different tokenization techniques.  

**Activities:**  
- Tokenize a text using the `transformers` package.  
- Tokenize text with stopwords as delimiters.  

**Tools:**  
Python, NLTK, spaCy  

---

### üî† **Task 3: Word Generation using LSTM**
**Objective:**  
Understand and analyze algorithms for word generation.  

**Activities:**  
- Build and train a **Single Layer LSTM Model** for text generation.  

**Tools:**  
Python, NLTK, spaCy  

---

### üîç **Task 4: Morphology-based Word Embedding**
**Objective:**  
Develop algorithms to analyze the morphology of words in documents.  

**Activities:**  
- Perform stemming and lemmatization.  
- Identify morphological features of word forms.  

**Tools:**  
Python, NLTK, spaCy  

---

### üî° **Task 5: Developing N-Grams**
**Objective:**  
Generate N-Grams from text documents for language modeling.  

**Activities:**  
- Create unigrams, bigrams, and trigrams.  
- Implement text generation using the N-Gram model.  

**Tools:**  
Python, NLTK, spaCy  

---

### üìà **Task 6: N-Gram Smoothing**
**Objective:**  
Apply smoothing techniques to improve N-Gram model accuracy.  

**Activities:**  
- Implement **Laplace** and **Good-Turing** smoothing methods.  

**Tools:**  
Python, NLTK, spaCy  

---

### üè∑Ô∏è **Task 7: POS Tagging using Hidden Markov Model (HMM)**
**Objective:**  
Perform Part-of-Speech tagging using the Hidden Markov Model.  

**Activities:**  
- Train and test an HMM-based POS tagger.  
- Visualize results using Pandas.  

**Tools:**  
Python, Pandas, NLTK, spaCy, Gensim  

---

### üî¢ **Task 8: POS Tagging using Viterbi Decoding**
**Objective:**  
Improve POS tagging with Viterbi Decoding and log-linear models.  

**Activities:**  
- Implement **Viterbi Algorithm** for POS tagging.  
- Build a **Log-linear model** and compare it with HMM performance.  

**Tools:**  
Python, NLTK, spaCy, Gensim  

---

### üåê **Task 9: Building POS Tagger for Unstructured Web Documents**
**Objective:**  
Develop a POS tagger for unstructured text extracted from the web.  

**Activities:**  
- Extract structured data from unstructured content.  
- Train a neural model using **PyTorch** or **Keras** for tagging.  

**Tools:**  
Python, PyTorch, Keras  

---

### üß© **Task 10: Chunking for Web Documents**
**Objective:**  
Perform text chunking to create structured sections in web documents.  

**Activities:**  
- Apply content chunking on web data.  
- Design precise and engaging web page sections.  

**Tools:**  
Python, PyTorch, Keras  

---

### ü™Ñ **Task 11: Building Chunker for Web Documents**
**Objective:**  
Develop an automated chunker for content extraction and processing.  

**Activities:**  
- Extract and process key information from web pages.  
- Implement text mining and chunk-based information retrieval.  

**Tools:**  
Python, PyTorch, Keras  

---

### üìä **Task 12: Python Data Visualization Libraries**
**Objective:**  
Visualize NLP data using Python visualization tools.  

**Activities:**  
- Create frequency plots, bar charts, and word clouds.  

**Tools:**  
Python, Matplotlib, Seaborn  

---

## üöÄ **Part 2 ‚Äî Use Cases**

### üåè **Use Case 2: Machine Translation (English ‚Üí Hindi)**
**Objective:**  
Develop a machine translation system from English to Hindi using pre-trained models.  

**Activities:**  
- Use the **Transformers** library to load a pre-trained model (e.g., `Helsinki-NLP/opus-mt-en-hi`).  
- Translate English sentences into Hindi.  
- Evaluate translation performance and fluency.  

**Tools:**  
Python, Transformers, Hugging Face Models, NLTK, spaCy  

---

## üß∞ **Tools & Libraries Used**
- **Programming Language:** Python  
- **Libraries:** NLTK, spaCy, Gensim, Matplotlib, Seaborn, Transformers  
- **Frameworks:** PyTorch, Keras  

